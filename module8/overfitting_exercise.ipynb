{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting Exercise\n",
    "In this exercise, we'll build a model that, as you'll see, dramatically overfits the training data. This will allow you to see what overfitting can \"look like\" in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we'll use gradient boosted trees. In order to implement this model, we'll use the XGBoost package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /opt/conda/lib/python3.6/site-packages (0.90)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from xgboost) (1.12.1)\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from xgboost) (0.19.1)\r\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we define a few helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows in a dataframe\n",
    "def nrow(df): \n",
    "    return(len(df.index))\n",
    "\n",
    "# number of columns in a dataframe\n",
    "def ncol(df): \n",
    "    return(len(df.columns))\n",
    "\n",
    "# flatten nested lists/arrays\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "\n",
    "# combine multiple arrays into a single list\n",
    "def c(*args):\n",
    "    return(flatten([item for item in args]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we're going to try to predict the returns of the S&P 500 ETF. This may be a futile endeavor, since many experts consider the S&P 500 to be essentially unpredictable, but it will serve well for the purpose of this exercise. The following cell loads the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SPYZ.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data file has four columns, `Date`, `Close`, `Volume` and `Return`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Return</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>146.8750</td>\n",
       "      <td>3172700</td>\n",
       "      <td>0.001598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000-01-03</td>\n",
       "      <td>145.4375</td>\n",
       "      <td>8164300</td>\n",
       "      <td>-0.009787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2000-01-04</td>\n",
       "      <td>139.7500</td>\n",
       "      <td>8089800</td>\n",
       "      <td>-0.039106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000-01-05</td>\n",
       "      <td>140.0000</td>\n",
       "      <td>12177900</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-01-06</td>\n",
       "      <td>137.7500</td>\n",
       "      <td>6227200</td>\n",
       "      <td>-0.016071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date     Close    Volume    Return\n",
       "0  1999-12-31  146.8750   3172700  0.001598\n",
       "1  2000-01-03  145.4375   8164300 -0.009787\n",
       "2  2000-01-04  139.7500   8089800 -0.039106\n",
       "3  2000-01-05  140.0000  12177900  0.001789\n",
       "4  2000-01-06  137.7500   6227200 -0.016071"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0097872340425531907"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.loc[1,\"Close\"] - df.loc[0, \"Close\"]) / df.loc[0, \"Close\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4780"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = nrow(df)\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll form our predictors/features. In the cells below, we create four types of features. We also use a parameter, `K`, to set the number of each type of feature to build. With a `K` of 25, 100 features will be created. This should already seem like a lot of features, and alert you to the potential that the model will be overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = []\n",
    "\n",
    "# we'll create a new DataFrame to hold the data that we'll use to train the model\n",
    "# we'll create it from the `Return` column in the original DataFrame, but rename that column `y`\n",
    "model_df = pd.DataFrame(data = df['Return']).rename(columns = {\"Return\" : \"y\"})\n",
    "\n",
    "# IMPORTANT: this sets how many of each of the following four predictors to create\n",
    "K = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you write the code to create the four types of predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for L in range(1,K+1): \n",
    "    # this predictor is just the return L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `R1`, `R2`, etc.\n",
    "    pR = \"\".join([\"R\",str(L)]) \n",
    "    predictors.append(pR)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the return from L days before to the ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pR] = df.loc[i-L, \"Return\"]\n",
    "\n",
    "    # this predictor is the return L days ago, squared, where L goes from 1 to K\n",
    "    # these predictors will be named `Rsq1`, `Rsq2`, etc.\n",
    "    pR2 = \"\".join([\"Rsq\",str(L)])\n",
    "    predictors.append(pR2)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the squared return from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        model_df.loc[i, pR2] = df.loc[i-L, \"Return\"] **2\n",
    "\n",
    "    # this predictor is the log volume L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `V1`, `V2`, etc.\n",
    "    pV = \"\".join([\"V\",str(L)])\n",
    "    predictors.append(pV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the log of the volume from L days before to the ith row of this predictor \n",
    "        # in `model_df`\n",
    "        # Add 1 to the volume before taking the log\n",
    "        model_df.loc[i, pV] = math.log(1.0 + df.loc[i-L, \"Volume\"])\n",
    "\n",
    "    # this predictor is the product of the return and the log volume from L days ago, where L goes from 1 to K\n",
    "    # these predictors will be named `RV1`, `RV2`, etc.\n",
    "    pRV = \"\".join([\"RV\",str(L)])\n",
    "    predictors.append(pRV)\n",
    "    for i in range(K+1,n): \n",
    "        # TODO: fill in the code to assign the product of the return and the log volume from L days before to the\n",
    "        # ith row of this predictor in `model_df`\n",
    "        model_df.loc[i, pRV] = model_df.loc[i, pR] * model_df.loc[i, pV]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the predictors we've created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>R1</th>\n",
       "      <th>Rsq1</th>\n",
       "      <th>V1</th>\n",
       "      <th>RV1</th>\n",
       "      <th>R2</th>\n",
       "      <th>Rsq2</th>\n",
       "      <th>V2</th>\n",
       "      <th>RV2</th>\n",
       "      <th>R3</th>\n",
       "      <th>...</th>\n",
       "      <th>V23</th>\n",
       "      <th>RV23</th>\n",
       "      <th>R24</th>\n",
       "      <th>Rsq24</th>\n",
       "      <th>V24</th>\n",
       "      <th>RV24</th>\n",
       "      <th>R25</th>\n",
       "      <th>Rsq25</th>\n",
       "      <th>V25</th>\n",
       "      <th>RV25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>16.198698</td>\n",
       "      <td>-0.121956</td>\n",
       "      <td>-0.018688</td>\n",
       "      <td>...</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "      <td>0.026421</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>16.209371</td>\n",
       "      <td>0.428273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>15.892349</td>\n",
       "      <td>-0.234024</td>\n",
       "      <td>-0.007529</td>\n",
       "      <td>...</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "      <td>-0.009302</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>15.695540</td>\n",
       "      <td>-0.145995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>16.221058</td>\n",
       "      <td>0.264474</td>\n",
       "      <td>-0.014726</td>\n",
       "      <td>...</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>15.959991</td>\n",
       "      <td>0.076664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>15.929221</td>\n",
       "      <td>-0.273290</td>\n",
       "      <td>0.016304</td>\n",
       "      <td>...</td>\n",
       "      <td>15.858172</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "      <td>-0.010865</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>16.372203</td>\n",
       "      <td>-0.177882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>15.494960</td>\n",
       "      <td>0.529838</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>15.387039</td>\n",
       "      <td>0.017437</td>\n",
       "      <td>-0.017157</td>\n",
       "      <td>...</td>\n",
       "      <td>16.562480</td>\n",
       "      <td>-0.054770</td>\n",
       "      <td>-0.011285</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>15.858172</td>\n",
       "      <td>-0.178954</td>\n",
       "      <td>0.041520</td>\n",
       "      <td>0.001724</td>\n",
       "      <td>16.461827</td>\n",
       "      <td>0.683503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            y        R1      Rsq1         V1       RV1        R2      Rsq2  \\\n",
       "100  0.016304 -0.014726  0.000217  15.892349 -0.234024 -0.007529  0.000057   \n",
       "101 -0.017157  0.016304  0.000266  16.221058  0.264474 -0.014726  0.000217   \n",
       "102  0.001133 -0.017157  0.000294  15.929221 -0.273290  0.016304  0.000266   \n",
       "103  0.034194  0.001133  0.000001  15.387039  0.017437 -0.017157  0.000294   \n",
       "104  0.000657  0.034194  0.001169  15.494960  0.529838  0.001133  0.000001   \n",
       "\n",
       "            V2       RV2        R3    ...           V23      RV23       R24  \\\n",
       "100  16.198698 -0.121956 -0.018688    ...     15.959991  0.076664 -0.009302   \n",
       "101  15.892349 -0.234024 -0.007529    ...     16.372203 -0.177882  0.004804   \n",
       "102  16.221058  0.264474 -0.014726    ...     16.461827  0.683503 -0.010865   \n",
       "103  15.929221 -0.273290  0.016304    ...     15.858172 -0.178954  0.041520   \n",
       "104  15.387039  0.017437 -0.017157    ...     16.562480 -0.054770 -0.011285   \n",
       "\n",
       "        Rsq24        V24      RV24       R25     Rsq25        V25      RV25  \n",
       "100  0.000087  15.695540 -0.145995  0.026421  0.000698  16.209371  0.428273  \n",
       "101  0.000023  15.959991  0.076664 -0.009302  0.000087  15.695540 -0.145995  \n",
       "102  0.000118  16.372203 -0.177882  0.004804  0.000023  15.959991  0.076664  \n",
       "103  0.001724  16.461827  0.683503 -0.010865  0.000118  16.372203 -0.177882  \n",
       "104  0.000127  15.858172 -0.178954  0.041520  0.001724  16.461827  0.683503  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a DataFrame that holds the recent volatility of the ETF's returns, as measured by the standard deviation of a sliding window of the past 20 days' returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df = pd.DataFrame(data = df[['Return']])\n",
    "\n",
    "for i in range(K+1,n): \n",
    "    # TODO: create the code to assign the standard deviation of the return from the time period starting \n",
    "    # 20 days before day i, up to the day before day i, to the ith row of `vol_df`\n",
    "    vol_df.loc[i, 'vol'] = np.std(vol_df.loc[i-20:i-1,'Return'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Return</th>\n",
       "      <th>vol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.016304</td>\n",
       "      <td>0.013069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.017157</td>\n",
       "      <td>0.013615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.014007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.034194</td>\n",
       "      <td>0.014008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.015792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Return       vol\n",
       "100  0.016304  0.013069\n",
       "101 -0.017157  0.013615\n",
       "102  0.001133  0.014007\n",
       "103  0.034194  0.014008\n",
       "104  0.000657  0.015792"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol_df.iloc[100:105,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our data, we can start thinking about training a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training, we'll use all the data except for the first K days, for which the predictors' values are NaNs\n",
    "model = model_df.iloc[K:n,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below, first split the data into train and test sets, and then split off the targets from the predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "train_size = 2.0/3.0\n",
    "breakpoint = round(nrow(model) * train_size)\n",
    "\n",
    "# TODO: fill in the code to split off the chunk of data up to the breakpoint as the training set, and\n",
    "# assign the rest as the test set.\n",
    "training_data = model.iloc[:breakpoint,:]\n",
    "test_data = model.iloc[breakpoint:,:]\n",
    "\n",
    "# TODO: Split training data and test data into targets (Y) and predictors (X), for the training set and the test set\n",
    "X_train = training_data.iloc[:, 1:]\n",
    "Y_train = training_data.iloc[:, 0]\n",
    "X_test = test_data.iloc[:, 1:]\n",
    "Y_test = test_data.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now that we have our data, let's train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/conda/lib/python3.6/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    }
   ],
   "source": [
    "# DMatrix is a internal data structure that used by XGBoost which is optimized for both memory efficiency \n",
    "# and training speed. \n",
    "dtrain = xgb.DMatrix(X_train, Y_train)\n",
    "\n",
    "# Train the XGBoost model\n",
    "param = { 'max_depth':20, 'silent':1 }\n",
    "num_round = 20\n",
    "xgModel = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's predict the returns for the S&P 500 ETF in both the train and test periods. If the model is successful, what should the train and test accuracies look like? What would be a key sign that the model has overfit the training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: Before you run the next cell, write down what you expect to see if the model is overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the predictions on the test data\n",
    "preds_train = xgModel.predict(xgb.DMatrix(X_train))\n",
    "preds_test = xgModel.predict(xgb.DMatrix(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly look at the mean squared error of the predictions on the training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the mean squared error on the training set\n",
    "msetrain = sum((preds_train - Y_train)**2)/nrow(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate the mean squared error on the test set\n",
    "msetest = sum((preds_test - Y_test)**2)/nrow(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the mean squared error on the test set is an order of magnitude greater than on the training set. Not a good sign. Now let's do some quick calculations to gauge how this would translate into performance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6478984898>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# combine prediction arrays into a single list\n",
    "predictions = c(preds_train, preds_test)\n",
    "responses = c(Y_train, Y_test)\n",
    "\n",
    "# as a holding size, we'll take predicted return divided by return variance\n",
    "# this is mean-variance optimization with a single asset\n",
    "vols = vol_df.loc[K:n,'vol']\n",
    "position_size = predictions / vols ** 2\n",
    "\n",
    "# TODO: Calculate pnl. Pnl in each time period is holding * realized return.\n",
    "performance = position_size * responses\n",
    "\n",
    "# plot simulated performance\n",
    "plt.plot(np.cumsum(performance))\n",
    "plt.ylabel('Simulated Performance')\n",
    "plt.axvline(x=breakpoint, c = 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our simulated returns accumulate throughout the training period, but they are absolutely flat in the testing period. The model has no predictive power whatsoever in the out-of-sample period.\n",
    "\n",
    "Can you think of a few reasons our simulation of performance is unrealistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Answer the above question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If you need a little assistance, check out the [solution](overfitting_exercise_solution.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
